# -*- coding: utf-8 -*-
"""SIN J comp.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/14VGF6SgCNv5njAGEuzV7B89zjwVb1V_q
"""

!pip install pycryptodome

!pip install Pyrebase4

import pyrebase

import json

config={
    "apiKey": "AIzaSyA8XoaauKU4oEx1JS9ZoJar-NbJgTpUk4A",
    "authDomain": "sin-project-274db.firebaseapp.com",
    "databaseURL": "https://sin-project-274db-default-rtdb.firebaseio.com",
    "projectId": "sin-project-274db",
    "storageBucket": "sin-project-274db.appspot.com",
    "messagingSenderId": "76056950045",
    "databaseURL":"https://sin-project-274db-default-rtdb.firebaseio.com/",
    "appId": "1:76056950045:web:972c15f6aee1801f571df4",
    "measurementId": "G-PNW7N4K617"
}
firebase=pyrebase.initialize_app(config)
database=firebase.database()

class student:
    def __init__(self,name,roll_no,skillset,bio, location,hobbies):
        self.name = name
        self.roll_no = roll_no
        self.skillset = skillset
        self.bio = bio
        self.location = location
        self.hobbies = hobbies
        self.friends=[]
        jsonObj = json.dumps(self.__dict__)
        database.child("users").child(name).set(jsonObj)

A=student("A",1,['C++','C','Python','Java'],"Hello I am A", "Chennai",['Reading','Cycling'])
B=student("B",2,['HTML','React JS', 'CSS'],"Hey","Mumbai",['Drawing'])
C=student("C",3,['JavaScript'],"Hello I am C. I am interested in coding.", "Chennai",['Painting'])
D=student("D",4,['Mongo DB','SQL','Python'],"Hi","Delhi",[''])
E = student("E",5,['Springboot','Java'],"Hey coders","Pune",['Cycling','Rowing','Cricket','Coding','Singing'])
F = student("F",6,['Python','C++','Java'],"Hey coders","Chennai",['Cycling','Running','Coding','Singing'])

G = student("G",7,['Springboot','Java','Spring'],"Hello gang!!","Pune",['Singing','Music'])

"""#Module 1
Connect Disconnect
"""

def make_a_friend(A,B):
    data = database.child("users").child(A.name).get().val()
    if type(data)==str:
        data = json.loads(data)
    else:
        data = dict(data)
    if B.name not in data['friends']:  #to make sure connections are not repeated
      data['friends'].append(B.name)
    database.child("users").child(A.name).update(data)
    data = database.child("users").child(B.name).get().val()
    if type(data)==str:
        data = json.loads(data)
    else:
        data = dict(data)
    if A.name not in data['friends']:  #to make sure connections are not repeated
      data['friends'].append(A.name)
    database.child("users").child(B.name).update(data)

def remove_friend(A,B):
        data = database.child("users").child(A.name).get().val()
        data = dict(data)
        data['friends'].remove(B.name)
        database.child("users").child(A.name).update(data)
        data = database.child("users").child(B.name).get().val()
        data = dict(data)
        data['friends'].remove(A.name)
        database.child("users").child(B.name).update(data)

str==type(database.child("users").child("A").get().val())

json.loads(database.child("users").child("A").get().val())

make_a_friend(A,D)
make_a_friend(A,B)
make_a_friend(B,C)
make_a_friend(A,C)

make_a_friend(A,D)

def getUser():
    db=database.child("users").get()
    l = []
    for i in db.each():
        l.append(i.val())
    return l

getUser()

import networkx as nx

G = nx.Graph()

def GraphPlot():
    l = getUser()
    for i in l:
        if type(i)==str:
            G.add_node(json.loads(i)['name'])
        else:
            G.add_node(i['name'])
        # print(json.loads(i['name']))
    for i in l:
        if type(i)!=str:
            for j in i['friends']:
                G.add_edge(i["name"],j)
    nx.draw(G, with_labels=True, font_weight='bold')

GraphPlot()

import matplotlib.pyplot as plt

"""#Module 2
Social connectivity
"""

def UserPopularity(A):
  return G.degree[A.name]

UserPopularity(B)

def MostPopular():
  lst=sorted(G.degree, key=lambda x: x[1], reverse=True)
  print("Most famous user: ",[lst[i][0] for i in range(len(lst)) if lst[i][1]==lst[0][1]],"\nLeast famous user: ",[lst[i][0] for i in range(len(lst)) if lst[i][1]==lst[-1][1]])

MostPopular()

"""##Module 3
Degree of Connection
"""

def findDegree(A,B):
        flag=0
        data = database.child("users").child(A.name).get().val()
        if type(data)==str:
          data = json.loads(data)
        else:
          data = dict(data)
        if B.name in data['friends']:
          return 1
        if flag==0:
          for i in data['friends']:
            data1 = database.child("users").child(i).get().val()
            if type(data)==str:
              data1 = json.loads(data1)
            else:
              data1 = dict(data1)
            if B.name in data1['friends']:
              return 2
        if flag == 0:
            return 3

findDegree(D,E)

"""#Module 4 & 5
Similarity Score & Suggestion
"""

import nltk
nltk.download('punkt')
nltk.download('stopwords')

import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import numpy as np
def suggest(A):
    # corpus = []
    d = {}
    l = getUser()
    # m = 400
    for i in l:
        c = []
        if type(i)!=str:
            c.append(i['location'])
            for j in i['skillset']:
                c.append(j)
            for j in i['hobbies']:
                c.append(j)
            d[i['name']] = [' '.join(c)]
        else:
            p = json.loads(i)
            c.append(p['location'])
            for j in p['skillset']:
                c.append(j)
            for j in p['hobbies']:
                c.append(j)
            d[p['name']] = [' '.join(c)]
    df = pd.DataFrame(d)
    tf = TfidfVectorizer()
    doc_vec = tf.fit_transform(df.iloc[0])
    df2 = pd.DataFrame(doc_vec.toarray().transpose(),
                   index=tf.get_feature_names_out())
    df2.columns = df.columns
    # for i in df2.columns:
    #      print(cosine_similarity(np.array(df2[A['name']]),np.array(df2[i])))
    # p = {}
    # if type(A)!=str:
    #     p = json.loads(A)
    # else:
    #     p = A
    p = {}
    for i in df2.columns:
        p[i] = cosine_similarity(np.array([df2[A.name]]),np.array([df2[i]]))[0][0]

    q = {k: v for k, v in sorted(p.items() , key=lambda item: item[1], reverse = True) if k!=A.name}
    print(q)
    # print(type(np.array(df2[p['name']])))
    #     corpus+=c
    # print(m)
    # cv = CountVectorizer(max_features = m)
    # corpus = list(set(corpus))
    # vectors = cv.fit_transform(corpus).toarray()
    # print(vectors)

suggest(A)

def jaccard_similarity(a, b):
    # convert to set
    a = set(a)
    b = set(b)
    # calucate jaccard similarity
    j = float(len(a.intersection(b))) / len(a.union(b))
    return j

def suggestUsingJaccard(A):
    # corpus = []
    d = {}
    l = getUser()
    # m = 400
    for i in l:
        c = []
        if type(i)!=str:
            c.append(i['location'])
            for j in i['skillset']:
                c.append(j)
            for j in i['hobbies']:
                c.append(j)
            d[i['name']] = [' '.join(c)]
        else:
            p = json.loads(i)
            c.append(p['location'])
            for j in p['skillset']:
                c.append(j)
            for j in p['hobbies']:
                c.append(j)
            d[p['name']] = [' '.join(c)]
    df = pd.DataFrame(d)
    tf = TfidfVectorizer()
    doc_vec = tf.fit_transform(df.iloc[0])
    df2 = pd.DataFrame(doc_vec.toarray().transpose(),
                   index=tf.get_feature_names_out())
    df2.columns = df.columns
    p = {}
    for i in df2.columns:
        p[i] = jaccard_similarity(df2[A.name],df2[i])



    q = {k: v for k, v in sorted(p.items() , key=lambda item: item[1], reverse = True) if k!=A.name}
    print(q)

suggestUsingJaccard(A)

"""#Module 6
Community classification
"""

def clusters():
    l = getUser()
    corpus=[]
    for i in l:
        if type(i)!=str:
            corpus.append(i['location'])
            for j in i['skillset']:
                corpus.append(j)
            for j in i['hobbies']:
                corpus.append(j)
        else:
            p = json.loads(i)
            corpus.append(p['location'])
            for j in p['skillset']:
                corpus.append(j)
            for j in p['hobbies']:
                corpus.append(j)
    corpus=list(set(corpus))
    # print(corpus)
    for i in corpus:
        cluster=[]
        for j in l:
            if type(j)!=str:
                if i == j['location']:
                    cluster.append(j['name'])
                if i in j['skillset']:
                    cluster.append(j['name'])
                if i in j['hobbies']:
                    cluster.append(j['name'])
            else:
                p = json.loads(j)
                if i == p['location']:
                    cluster.append(p['name'])
                if i in p['skillset']:
                    cluster.append(p['name'])
                if i in p['hobbies']:
                    cluster.append(p['name'])
        if(len(cluster)>1):
            print("Cluster ",i," :",cluster)

clusters()